{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0yikAPYtU-u"
      },
      "outputs": [],
      "source": [
        "# Installation\n",
        "!pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API Key setup\n",
        "from google.colab import userdata\n",
        "GEMINI_API_KEY: str = userdata.get('Apikey')\n",
        "if(GEMINI_API_KEY):\n",
        "  print(\"API Key found\")\n",
        "else:\n",
        "  print(\"API Key not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwauhs8ItgPc",
        "outputId": "d0b6572d-3a48-4c51-c711-1a87c48ce89d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initilize and configure the client\n",
        "# Select the model\n",
        "from google import genai\n",
        "from google.genai import Client\n",
        "\n",
        "client: Client = genai.Client(\n",
        "    api_key=GEMINI_API_KEY,\n",
        ")\n",
        "\n",
        "model: str = \"gemini-2.0-flash-exp\""
      ],
      "metadata": {
        "id": "-I7eB4Wbts3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(path=video_file_name)\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "      print('Waiting for video to be processed.')\n",
        "      time.sleep(10)\n",
        "      video_file = client.files.get(name=video_file.name or \"\")\n",
        "\n",
        "  if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'Video processing complete: ' + (video_file.uri or \"\"))\n",
        "\n",
        "  return video_file\n",
        "\n",
        "intro_video = upload_video('/content/abu.mp4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIDjQx9Utw_8",
        "outputId": "369a9272-93b1-4b39-a3d3-64ea7752a388"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/mk4d4hje7sgb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "from google.genai.types import Content, Part\n",
        "prompt = \"\"\"Contextual Analysis\n",
        "\n",
        "\"What is the tone of the speaker in the video?\"\n",
        "\"What emotions are conveyed by the person in the video?\"\n",
        "Visual Insights\n",
        "\n",
        "\"Can you describe the colors and patterns visible in the background?\"\n",
        "\"Are there any noticeable objects or items in the scene, and what are they?\"\n",
        "Audio Details\n",
        "\n",
        "\"Is there any background noise or music in the video?\"\n",
        "\"Are there any non-verbal sounds, like laughter or sighs?\"\n",
        "Scene Transitions\n",
        "\n",
        "\"How many distinct scenes are present in the video?\"\n",
        "\"Are there any noticeable changes in lighting or camera angles between scenes?\"\n",
        "Speaker Attributes\n",
        "\n",
        "\"How would you describe the speakerâ€™s appearance, such as clothing and hairstyle?\"\n",
        "\"Does the speaker exhibit any gestures or body language that stand out?\"\n",
        "Comprehension Check\n",
        "\n",
        "\"What is the overall message or purpose of the video?\"\n",
        "\"Does the content suggest any specific context, like a professional or casual setting?\"\n",
        "\n",
        "         \"\"\"\n",
        "\n",
        "video = intro_video\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model,\n",
        "    contents=[\n",
        "        Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                Part.from_uri(\n",
        "                    file_uri=video.uri or \"\",\n",
        "                    mime_type=video.mime_type or \"\"),\n",
        "                ]),\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "iJOPwLI4uaVm",
        "outputId": "c3342689-bed5-4a6d-f76c-12c56394069b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, let's break down this video based on your questions:\n\n**Contextual Analysis**\n\n*   **Tone of the Speaker:** The speaker's tone is neutral and matter-of-fact. He's providing information in a straightforward manner without much emotional inflection. \n*   **Emotions Conveyed:** There aren't strong emotions being conveyed. The speaker seems calm and perhaps slightly reserved. There's a subtle smile at the end, which might suggest a hint of friendliness.\n\n**Visual Insights**\n\n*   **Colors and Patterns:** The background is a mix of muted tones. We see a pale yellow wall, a brown door frame, and a striking red curtain with a busy, ornate pattern in gold or yellow. The curtain appears to be a prominent design element.\n*   **Noticeable Objects:**\n    *   A refrigerator or freezer, likely made of metal, is visible on the left side of the frame.\n    *   A door frame, potentially leading to another room, is partially visible.\n    *   A curtain or tapestry with a detailed, red and yellow pattern is on the right.\n    *   The speaker appears to be wearing a jacket and sweater.\n\n**Audio Details**\n\n*   **Background Noise or Music:** There is no noticeable background noise or music. The audio is primarily the speaker's voice.\n*   **Non-verbal Sounds:** There are no discernible non-verbal sounds such as laughter or sighs. The audio is clear and focused on the speaker's words.\n\n**Scene Transitions**\n\n*   **Distinct Scenes:** There is only one scene in this video. The camera remains in the same position throughout.\n*   **Changes in Lighting or Camera Angles:** There are no changes in lighting or camera angles. The scene is consistent throughout.\n\n**Speaker Attributes**\n\n*   **Appearance:** The speaker is a young man with dark hair and a mustache. He is wearing glasses, a green sweater, and a dark, green/teal-colored jacket. His hairstyle is neat and slightly parted to the side.\n*   **Gestures or Body Language:** The speaker primarily maintains a stationary position with minimal movement. He is not particularly expressive with his body language. At the end of the video, he shows a brief smile, which is the only notable gesture.\n\n**Comprehension Check**\n\n*   **Overall Message or Purpose:** The purpose of the video appears to be the speaker introducing himself, stating his name, age, and educational background. It's a brief self-introduction.\n*   **Specific Context:** The setting appears to be casual. The speaker seems to be filming in what is likely his home. There is no specific formal context apparent, making it seem like a simple, informal recording.\n\nIf you have another video you'd like analyzed, feel free to ask!\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GDq9HrEL1jRw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}